# ============================================================================
# EMULATOR TRAINING CONFIGURATION TEMPLATE
# ============================================================================
# Purpose: Train neural network emulators for cosmic shear data vectors
# Author: Béla Arwen
# Last Updated: November 2025
#
# USAGE:
#   1. Copy this file and rename (e.g., xi_high_accuracy.yaml)
#   2. Update the [PATHS] section with your directories
#   3. Update the [TRAINING DATA] section with your dataset names
#   4. Update the [ACCURACY] section for high/low accuracy settings
#   5. Run: python train_emulator.py --yaml <your_file>.yaml --probe cosmic_shear
# ============================================================================

# ============================================================================
# [BASIC SETTINGS]
# ============================================================================
timing: True
debug: False
stop_at_error: False

# ============================================================================
# [LIKELIHOOD CONFIGURATION]
# ============================================================================
# Defines the cosmological probe and accuracy settings
likelihood:
  lsst_y1.cosmic_shear:
    # Path to data files (relative to Cocoa root or absolute)
    path: ./projects/lsst_y1/data
    
    # Dataset file (contains covariance, masks, etc.)
    data_file: lsst_y1_train.dataset
    
    # -------- [ACCURACY SETTINGS] --------
    # For HIGH accuracy:  accuracyboost=4.0, integration_accuracy=1.0
    # For LOW accuracy:   accuracyboost=1.0, integration_accuracy=0.0
    accuracyboost: 4.0
    integration_accuracy: 1.0
    # -------------------------------------
    
    kmax_boltzmann: 5.0
    non_linear_emul: 2  # 1=EE2, 2=Halofit, 3=EFT
    IA_model: 0
    IA_redshift_evolution: 3

# ============================================================================
# [PARAMETERS]
# ============================================================================
# Cosmological and nuisance parameters
# NOTE: This section is typically identical across all emulator configs
params:
  # -------- Cosmological Parameters --------
  As_1e9:
    prior: {min: 0.5, max: 5}
    ref: {dist: norm, loc: 2.1, scale: 0.65}
    proposal: 0.4
    latex: 10^9 A_\mathrm{s}
    drop: true
    renames: A
  
  ns:
    prior: {min: 0.87, max: 1.07}
    ref: {dist: norm, loc: 0.96605, scale: 0.01}
    proposal: 0.01
    latex: n_\mathrm{s}
  
  H0:
    prior: {min: 55, max: 91}
    ref: {dist: norm, loc: 67.32, scale: 5}
    proposal: 3
    latex: H_0
  
  omegab:
    prior: {min: 0.03, max: 0.07}
    ref: {dist: norm, loc: 0.0495, scale: 0.004}
    proposal: 0.004
    latex: \Omega_\mathrm{b}
    drop: true
  
  omegam:
    prior: {min: 0.1, max: 0.9}
    ref: {dist: norm, loc: 0.316, scale: 0.02}
    proposal: 0.02
    latex: \Omega_\mathrm{m}
    drop: true
  
  # Fixed parameters
  w0pwa: {value: -1.0}
  w: {value: -1.0}
  mnu: {value: 0.06}
  tau: {value: 0.0697186, latex: \tau_\mathrm{reio}}
  
  # -------- LSST Nuisance Parameters --------
  # Photo-z uncertainties (5 tomographic bins)
  LSST_DZ_S1:
    prior: {dist: norm, loc: 0.0, scale: 0.018}
    ref: {dist: norm, loc: 0.0, scale: 0.018}
    proposal: 0.005
    latex: \Delta z_\mathrm{s,LSST}^1
  
  LSST_DZ_S2:
    prior: {dist: norm, loc: 0.0, scale: 0.015}
    ref: {dist: norm, loc: 0.0, scale: 0.015}
    proposal: 0.005
    latex: \Delta z_\mathrm{s,LSST}^2
  
  LSST_DZ_S3:
    prior: {dist: norm, loc: 0.0, scale: 0.011}
    ref: {dist: norm, loc: 0.0, scale: 0.011}
    proposal: 0.005
    latex: \Delta z_\mathrm{s,LSST}^3
  
  LSST_DZ_S4:
    prior: {dist: norm, loc: 0.0, scale: 0.017}
    ref: {dist: norm, loc: 0.0, scale: 0.017}
    proposal: 0.005
    latex: \Delta z_\mathrm{s,LSST}^4
  
  LSST_DZ_S5:
    prior: {dist: norm, loc: 0.0, scale: 0.017}
    ref: {dist: norm, loc: 0.0, scale: 0.017}
    proposal: 0.005
    latex: \Delta z_\mathrm{s,LSST}^5
  
  # Shear calibration (fixed at 0 for training)
  LSST_M1: {value: 0.0}
  LSST_M2: {value: 0.0}
  LSST_M3: {value: 0.0}
  LSST_M4: {value: 0.0}
  LSST_M5: {value: 0.0}
  
  # Intrinsic alignment parameters
  LSST_A1_1:
    prior: {min: -5, max: 5}
    ref: {dist: norm, loc: 0.7, scale: 0.5}
    proposal: 0.5
    latex: A_\mathrm{1-IA,LSST}^1
  
  LSST_A1_2:
    prior: {min: -5, max: 5}
    ref: {dist: norm, loc: -1.7, scale: 0.5}
    proposal: 0.5
    latex: A_\mathrm{1-IA,LSST}^2
  
  LSST_A2_1: {value: 0}
  LSST_A2_2: {value: 0}
  LSST_BTA_1: {value: 0}
  
  # -------- Derived Parameters --------
  # DO NOT REMOVE - Required for Cocoa weak lensing
  As:
    value: 'lambda As_1e9: 1e-9 * As_1e9'
    latex: A_\mathrm{s}
  
  wa:
    value: 'lambda w0pwa, w: w0pwa - w'
    latex: w_{a,\mathrm{DE}}
  
  omegabh2:
    value: 'lambda omegab, H0: omegab*(H0/100)**2'
    latex: \Omega_\mathrm{b} h^2
  
  omegach2:
    value: 'lambda omegam, omegab, mnu, H0: (omegam-omegab)*(H0/100)**2-(mnu*(3.046/3)**0.75)/94.0708'
    latex: \Omega_\mathrm{c} h^2
  
  omegal: {latex: \Omega_\Lambda}
  
  omegamh2:
    derived: 'lambda omegam, H0: omegam*(H0/100)**2'
    latex: \Omega_\mathrm{m} h^2
  
  sigma8: {latex: \sigma_8}
  
  s8h5:
    derived: 'lambda sigma8, H0: sigma8*(H0*1e-2)**(-0.5)'
    latex: \sigma_8/h^{0.5}
  
  s8omegamp5:
    derived: 'lambda sigma8, omegam: sigma8*omegam**0.5'
    latex: \sigma_8 \Omega_\mathrm{m}^{0.5}
  
  s8omegamp25:
    derived: 'lambda sigma8, omegam: sigma8*omegam**0.25'
    latex: \sigma_8 \Omega_\mathrm{m}^{0.25}
  
  age: {latex: '{\rm{Age}}/\mathrm{Gyr}'}
  rdrag: {latex: r_\mathrm{drag}}
  yheused: {latex: Y_P^\mathrm{BBN}}
  omegan2: {latex: \Omega_\mathrm{\\nu} h^2}
  
  omegan:
    derived: 'lambda omegan2, H0: omegan2/((H0/100)**2)'
    latex: \Omega_\mathrm{\\nu}

# ============================================================================
# [THEORY CODE CONFIGURATION]
# ============================================================================
# CAMB settings for generating theory predictions during training
theory:
  camb:
    path: ./external_modules/code/CAMB
    use_renames: True
    extra_args:
      halofit_version: takahashi
      # -------- Match accuracy to likelihood --------
      # For HIGH accuracy: AccuracyBoost=2.0
      # For LOW accuracy:  AccuracyBoost=1.0
      AccuracyBoost: 2.0
      # ---------------------------------------------
      lens_potential_accuracy: 1
      num_massive_neutrinos: 1
      nnu: 3.046
      dark_energy_model: ppf
      accurate_massive_neutrino_transfers: false
      k_per_logint: 20

# ============================================================================
# [EMULATOR TRAINING CONFIGURATION]
# ============================================================================
train_args:
  # -------- [MODEL OUTPUT PATHS] --------
  # Where to save the trained model
  cosmic_shear:
    path: ./cobaya/cobaya/theories/
    stop_at_error: True
    extra_args:
      device: 'cpu'  # or 'cuda' for GPU
      
      # Model file (will be created during training)
      file: ['./projects/lsst_y1/emulators/xi_high_accuracy']
      
      # Preprocessing parameters file (will be created during training)
      extra: ['./projects/lsst_y1/emulators/xi_high_accuracy.h5']
      
      # Parameters to emulate (12 total)
      ord: [['As_1e9', 'ns', 'H0', 'omegab', 'omegam',
             'LSST_DZ_S1', 'LSST_DZ_S2', 'LSST_DZ_S3', 'LSST_DZ_S4', 'LSST_DZ_S5',
             'LSST_A1_1', 'LSST_A1_2']]
      
      # Fast parameters (not emulated, computed analytically)
      fast_params: [['LSST_M1', 'LSST_M2', 'LSST_M3', 'LSST_M4', 'LSST_M5']]
      
      # Model architecture
      extrapar: [{
        'MLA': 'MLP',          # Model type: MLP or TRF (transformer)
        'INT_DIM_RES': 256,    # Hidden layer size
        'OUTPUT_DIM': 780      # Data vector length (ξ+ and ξ- combined)
      }]
      
      # Alternative: Transformer architecture (commented out)
      # extrapar: [{
      #   'MLA': 'TRF',
      #   'INT_DIM_RES': 256,
      #   'INT_DIM_TRF': 1024,
      #   'NC_TRF': 32,
      #   'OUTPUT_DIM': 780
      # }]
  
  # -------- [DATA PATHS] --------
  # Parameter covariance (for MCMC)
  parameter_covmat_file: './projects/lsst_y1/chains/MCMC1.covmat'
  
  # Data covariance matrix
  data_covmat_file: './projects/lsst_y1/data/lsst_y1_cov'
  
  # Training data directory
  training_data_path: './projects/lsst_y1/data/transfer_learning/'
  
  # -------- [TRAINING DATA FILES] --------
  # Training set
  n_train: 10000
  t_train: 16  # Number of parallel threads
  train_datavectors_file: 'train_datavectors_high_accuracy.npy'
  train_parameters_file: 'train_parameters_high_accuracy.txt'
  
  # Validation set
  n_valid: 1000
  t_valid: 8
  valid_datavectors_file: 'valid_datavectors_high_accuracy.npy'
  valid_parameters_file: 'valid_parameters_high_accuracy.txt'
  
  # Test set
  n_test: 1000
  t_test: 8
  test_datavectors_file: 'test_datavectors_high_accuracy.npy'
  test_parameters_file: 'test_parameters_high_accuracy.txt'
  
  # -------- [FIDUCIAL COSMOLOGY] --------
  # Center point for parameter sampling
  fiducial:
    As_1e9: 2.1
    ns: 0.96
    H0: 67.0
    omegab: 0.05
    omegam: 0.33
    LSST_DZ_S1: 0.0
    LSST_DZ_S2: 0.0
    LSST_DZ_S3: 0.0
    LSST_DZ_S4: 0.0
    LSST_DZ_S5: 0.0
    LSST_A1_1: 0.5
    LSST_A1_2: 0.0

# -------- [OUTPUT] --------
# Chain output directory (not used during training, but required)
output: ./projects/lsst_y1/chains/MCMC1

# ============================================================================
# END OF CONFIGURATION
# ============================================================================
